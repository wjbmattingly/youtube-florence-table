{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/synthetic/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Loading yifeihu/TF-ID-base requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/wjbmattingly/youtube-florence-table/notebooks/01-demo.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/wjbmattingly/youtube-florence-table/notebooks/01-demo.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39myifeihu/TF-ID-base\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wjbmattingly/youtube-florence-table/notebooks/01-demo.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m processor \u001b[39m=\u001b[39m AutoProcessor\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39myifeihu/TF-ID-base\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/synthetic/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:524\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39mif\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mquantization_config\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     _ \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mquantization_config\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 524\u001b[0m config, kwargs \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    525\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m    526\u001b[0m     return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    527\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[1;32m    528\u001b[0m     code_revision\u001b[39m=\u001b[39;49mcode_revision,\n\u001b[1;32m    529\u001b[0m     _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    530\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[1;32m    531\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    532\u001b[0m )\n\u001b[1;32m    534\u001b[0m \u001b[39m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mif\u001b[39;00m kwargs_orig\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtorch_dtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/synthetic/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:968\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m has_remote_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    967\u001b[0m has_local_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39min\u001b[39;00m CONFIG_MAPPING\n\u001b[0;32m--> 968\u001b[0m trust_remote_code \u001b[39m=\u001b[39m resolve_trust_remote_code(\n\u001b[1;32m    969\u001b[0m     trust_remote_code, pretrained_model_name_or_path, has_local_code, has_remote_code\n\u001b[1;32m    970\u001b[0m )\n\u001b[1;32m    972\u001b[0m \u001b[39mif\u001b[39;00m has_remote_code \u001b[39mand\u001b[39;00m trust_remote_code:\n\u001b[1;32m    973\u001b[0m     class_ref \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/synthetic/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:640\u001b[0m, in \u001b[0;36mresolve_trust_remote_code\u001b[0;34m(trust_remote_code, model_name, has_local_code, has_remote_code)\u001b[0m\n\u001b[1;32m    637\u001b[0m         _raise_timeout_error(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    639\u001b[0m \u001b[39mif\u001b[39;00m has_remote_code \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m has_local_code \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n\u001b[0;32m--> 640\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    641\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m requires you to execute the configuration file in that\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    642\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m repo on your local machine. Make sure you have read the code there to avoid malicious use, then\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m set the option `trust_remote_code=True` to remove this error.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m     )\n\u001b[1;32m    646\u001b[0m \u001b[39mreturn\u001b[39;00m trust_remote_code\n",
      "\u001b[0;31mValueError\u001b[0m: Loading yifeihu/TF-ID-base requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error."
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"yifeihu/TF-ID-base\", trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained(\"yifeihu/TF-ID-base\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<OD>\"\n",
    "\n",
    "url = \"https://huggingface.co/yifeihu/TF-ID-base/resolve/main/arxiv_2305_10853_5.png?download=true\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    pixel_values=inputs[\"pixel_values\"],\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=False,\n",
    "    num_beams=3\n",
    ")\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "parsed_answer = processor.post_process_generation(generated_text, task=\"<OD>\", image_size=(image.width, image.height))\n",
    "\n",
    "print(parsed_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
